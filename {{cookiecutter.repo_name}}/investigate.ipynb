{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d283bb3",
   "metadata": {},
   "source": [
    "# Analysis of the results\n",
    "\n",
    "This notebook investigates the results of all the model runs in the directory `results/runs`.\n",
    "\n",
    "## Imports and hardcoded variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec3a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "RESULTS_DIR = os.path.join(\"results\", \"runs\")\n",
    "ARVIZ_STYLE = \"arviz-redish\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c09cb",
   "metadata": {},
   "source": [
    "## Loading InferenceData objects\n",
    "\n",
    "The results of the analysis are stored as [`InferenceData`](https://arviz-devs.github.io/arviz/api/generated/arviz.InferenceData.html#arviz.InferenceData) objects in json files. The next cell loads these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5630a977",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'interaction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m         posterior \u001b[38;5;241m=\u001b[39m az\u001b[38;5;241m.\u001b[39mfrom_json(posterior_file)\n\u001b[1;32m     16\u001b[0m         posteriors[os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(run_dir)] \u001b[38;5;241m=\u001b[39m posterior\n\u001b[0;32m---> 18\u001b[0m \u001b[43mpriors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minteraction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'interaction'"
     ]
    }
   ],
   "source": [
    "run_dirs = [\n",
    "    os.path.join(RESULTS_DIR, d)\n",
    "    for d in os.listdir(RESULTS_DIR)\n",
    "    if os.path.isdir(os.path.join(\".\", RESULTS_DIR, d))\n",
    "]\n",
    "priors = {}\n",
    "posteriors = {}\n",
    "\n",
    "for run_dir in run_dirs:\n",
    "    prior_file = os.path.join(run_dir, \"prior.json\")\n",
    "    posterior_file = os.path.join(run_dir, \"posterior.json\")\n",
    "    if os.path.exists(prior_file):\n",
    "        priors[os.path.basename(run_dir)] = az.from_json(prior_file)\n",
    "    if os.path.exists(posterior_file):\n",
    "        posterior = az.from_json(posterior_file)\n",
    "        posteriors[os.path.basename(run_dir)] = posterior\n",
    "        \n",
    "priors[\"interaction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b983411",
   "metadata": {},
   "source": [
    "Some of the runs may also have results of exact cross-validation, also saved in json files. \n",
    "\n",
    "While its convenient to store the cross-validation files separately, for analysis it's nice to have them in the same place as their posteriors, so the next cell loads the cross-validation jsons and adds them to the matching posterior `InferenceData`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a22a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for posterior_name, posterior in posteriors.items():\n",
    "    llik_cv_file = os.path.join(RESULTS_DIR, posterior_name, \"llik_cv.json\")\n",
    "    if os.path.exists(llik_cv_file):\n",
    "        with open(llik_cv_file, \"r\") as f:\n",
    "            llik_cv_dict = json.load(f)\n",
    "        llik_cv = xarray.Dataset.from_dict(llik_cv_dict)\n",
    "        posterior.add_groups({\"log_likelihood_cv\": llik_cv})\n",
    "posteriors[\"interaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2163c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xarray.Dataset.from_dict(llik_cv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e9178",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = xarray.Dataset.from_dict(llik_cv_dict)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be5317",
   "metadata": {},
   "source": [
    "## Comparing predictions\n",
    "\n",
    "This cell uses arviz's [`compare`](https://arviz-devs.github.io/arviz/api/generated/arviz.compare.html) function to calculate the approximate leave-one-out expected log predictive density for each `InferenceData` object in the `posteriors` dictionary.\n",
    "\n",
    "It then calculates the same quantity using exact k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bf04de",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_loo_comparison = pd.DataFrame(\n",
    "    {k: az.loo(v) for k, v in posteriors.items()}\n",
    ").T[[\"loo\", \"loo_se\", \"p_loo\", \"warning\"]]\n",
    "\n",
    "posterior_kfold_comparison = pd.Series(\n",
    "    {\n",
    "        posterior_name:\n",
    "            float(\n",
    "                posterior.get(\"log_likelihood_cv\")[\"llik\"]\n",
    "                .mean(dim=[\"chain\", \"draw\"])\n",
    "                .sum()\n",
    "            )\n",
    "        for posterior_name, posterior in posteriors.items() \n",
    "        if \"log_likelihood_cv\" in posterior.groups()\n",
    "    }, name=\"kfold\"\n",
    ")\n",
    "\n",
    "posterior_comparison = posterior_loo_comparison.join(posterior_kfold_comparison)\n",
    "\n",
    "posterior_comparison.sort_values(\"kfold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8cf994",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b97d734",
   "metadata": {},
   "source": [
    "The last cell uses arviz to plot each posterior predictive distribution and saves the result to the `plots` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2604a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.style.use(ARVIZ_STYLE)\n",
    "\n",
    "x = xarray.DataArray(np.linspace(0, 1, 100))\n",
    "f, axes = plt.subplots(1, 3, figsize=[20, 5], sharey=True)\n",
    "axes = axes.ravel()\n",
    "for (posterior_name, posterior), ax in zip(posteriors.items(), axes):\n",
    "        az.plot_lm(\n",
    "            y=\"y\",\n",
    "            x=x,\n",
    "            idata=posterior,\n",
    "            y_hat=\"yrep\",\n",
    "            axes=ax,\n",
    "            kind_pp=\"hdi\",\n",
    "            y_kwargs={\"markersize\": 6, \"color\":\"black\"},\n",
    "            grid=False\n",
    "        )\n",
    "        ax.legend(frameon=False)\n",
    "        ax.set(title=posterior_name.replace(\"_\", \" \").capitalize(), ylabel=\"\")\n",
    "        ax.set_xticks([], [])\n",
    "axes[0].set_ylabel(\"y\")\n",
    "\n",
    "f.suptitle(\"Marginal posterior predictive distributions\")\n",
    "f.savefig(os.path.join(\"results\", \"plots\", \"posterior_predictive_comparison.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
